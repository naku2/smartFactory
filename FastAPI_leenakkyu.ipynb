{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkINjLFBxS9jihuxQLnxhO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naku2/smartFactory/blob/main/FastAPI_leenakkyu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import"
      ],
      "metadata": {
        "id": "9y5BMhGg9IAa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-a5XgGfJ9ETU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install fastapi nest-asyncio pyngrok uvicorn\n",
        "!pip install fastapi\n",
        "!pip install uvicorn\n",
        "!pip install pyngrok\n",
        "!pip install python-multipart==0.0.5\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 구동 확인"
      ],
      "metadata": {
        "id": "a8ShLpL09TnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from typing import Union\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from keras.models import load_model\n",
        "from starlette.requests import Request\n",
        "from fastapi import FastAPI, HTTPException, UploadFile, File\n",
        "from starlette.requests import Request\n",
        "from starlette.responses import HTMLResponse\n",
        "from keras.models import load_model\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/SK/smartFactory/transistor_cnn.h5')\n",
        "\n",
        "templates = Jinja2Templates(directory=\"/content/drive/MyDrive/SK/smartFactory\")\n",
        "app.mount(\"/static\", StaticFiles(directory=\"/content/drive/MyDrive/SK/smartFactory/static/\"))\n",
        "upload_folder = \"/content/drive/MyDrive/SK/smartFactory/static/\"\n",
        "\n",
        "image = Image.open('/content/drive/MyDrive/SK/smartFactory/static/big_head.jpeg')\n",
        "image = image.resize((224, 224)).convert('RGB')\n",
        "image = np.array(image) / 255.0\n",
        "image = image.reshape(-1, 224, 224, 3)\n",
        "\n",
        "pred = model.predict(image)\n",
        "result = np.argmax(pred)\n",
        "\n",
        "prediction_success = result\n",
        "prediction_result = result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBejpKIB9W3j",
        "outputId": "52af9294-29af-48ec-ee05-e38cc441259d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 3s 3s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gc3ycJBL9bE1",
        "outputId": "7c600f8f-ca88-4f71-cbcc-89a07135ab47"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API 제작"
      ],
      "metadata": {
        "id": "VpyLUy_S9f7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from typing import Union\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "from keras.models import load_model\n",
        "from starlette.requests import Request\n",
        "from fastapi import FastAPI, HTTPException, UploadFile, File\n",
        "from starlette.requests import Request\n",
        "from starlette.responses import HTMLResponse\n",
        "from keras.models import load_model\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import io\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "model = load_model('/content/drive/MyDrive/SK/smartFactory/transistor_cnn.h5')\n",
        "\n",
        "templates = Jinja2Templates(directory=\"/content/drive/MyDrive/SK/smartFactory\")\n",
        "app.mount(\"/static\", StaticFiles(directory=\"/content/drive/MyDrive/SK/smartFactory/static/\"))\n",
        "upload_folder = \"/content/drive/MyDrive/SK/smartFactory/static/\"\n",
        "\n",
        "\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def read_root(request: Request):\n",
        "    return templates.TemplateResponse(\"main.html\", {\"request\": request})\n",
        "\n",
        "@app.get(\"/predict\", response_class=HTMLResponse)\n",
        "async def read_predict(prediction_success: bool = True):\n",
        "    return templates.TemplateResponse(\"predict.html\", {\"prediction_success\": prediction_success, \"image_path\": \"/static/image_filename.jpg\"})\n",
        "\n",
        "@app.post(\"/uploadimage/\")\n",
        "async def upload_image(request: Request, image: UploadFile = File(...)):\n",
        "    try:\n",
        "        with open(os.path.join(upload_folder, image.filename), \"wb\") as buffer:\n",
        "            shutil.copyfileobj(image.file, buffer)\n",
        "\n",
        "        image = Image.open(io.BytesIO(await image.read()))\n",
        "        image = image.resize((224, 224)).convert('RGB')\n",
        "        image = np.array(image) / 255.0\n",
        "        image = image.reshape(-1, 224, 224, 3)\n",
        "\n",
        "        pred = model.predict(image)\n",
        "        result = np.argmax(pred)\n",
        "\n",
        "        prediction_success = result\n",
        "        prediction_result = result\n",
        "\n",
        "        return templates.TemplateResponse(\"predict.html\", {\"request\": request, \"prediction_success\": prediction_success, \"prediction_result\": prediction_result, \"image_path\": f\"/static/{image.filename}\"})\n",
        "\n",
        "    except Exception as e:\n",
        "        # 예외 발생 시 에러 메시지를 출력하여 디버깅\n",
        "        print(\"Error occurred:\", e)\n",
        "        # 예외가 발생한 경우에도 적절한 응답을 반환하도록 처리\n",
        "        return templates.TemplateResponse(\"predict.html\", {\"request\": request, \"prediction_success\": False, \"prediction_result\": \"Error\", \"image_path\": f\"/static/{image.filename}\"})\n",
        "\n"
      ],
      "metadata": {
        "id": "DMZwiC2T9idX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ngrok 환경설정"
      ],
      "metadata": {
        "id": "2RgL4gDy9pJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import threading\n",
        "\n",
        "!ngrok authtoken '2SrfOHr1mTjMqKQmg6UGJ7fHt1m_fbeBZagYob3KbzxjKGXf'\n",
        "\n",
        "ngrok.kill()\n",
        "\n",
        "url = ngrok.connect(8000)  # FastAPI의 기본 포트는 8000입니다.\n",
        "print('Public URL:', url)\n",
        "\n",
        "def run():\n",
        "    config = uvicorn.Config(app, host=\"0.0.0.0\", port=8000, log_level=\"info\", access_log=False)\n",
        "    config.access_log_file = \"log.txt\"  # 로그를 파일로 저장하는 설정\n",
        "    server = uvicorn.Server(config)\n",
        "    server.run()\n",
        "\n",
        "# run 함수를 쓰레드로 실행\n",
        "threading.Thread(target=run).start()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4EzNMmpb9rev",
        "outputId": "c6b7af5e-689e-424c-d3a3-311a63cabf62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-07-21T13:12:12+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://90d5-35-236-210-37.ngrok-free.app\" -> \"http://localhost:8000\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lsof -i :8000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkO6L25l9t2g",
        "outputId": "24a21f0b-c3e3-47ff-f821-d15b6e249a5f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [225]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COMMAND PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "python3 225 root   53u  IPv4  47448      0t0  TCP *:8000 (LISTEN)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kill -9 387"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBtACri69vBH",
        "outputId": "6ad17bd2-286a-4828-a1c0-48649cedbc5a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: kill: (387) - No such process\n"
          ]
        }
      ]
    }
  ]
}